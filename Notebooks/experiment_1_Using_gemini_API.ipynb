{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOndoAJhFrDWD9BqQfSyCb0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azmd801/Smart-ATS/blob/main/Notebooks/experiment_1_Using_gemini_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install PyPDF2\n",
        "!pip install google.generativeai  # Please replace this with the correct package name if available.\n",
        "!pip install python-dotenv\n",
        "!pip install python-docx"
      ],
      "metadata": {
        "id": "b0bIrbs_KCuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import streamlit as st\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import PyPDF2 as pdf\n",
        "from dotenv import load_dotenv\n",
        "import json\n",
        "from docx import Document\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "AxAstHPhDWtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('GOOGLE_GEMINI_API')"
      ],
      "metadata": {
        "id": "T8uNOmSKQmsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "id": "OJHbp5EGQhxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEdMItI57VEy"
      },
      "outputs": [],
      "source": [
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "def get_gemini_repsonse(input):\n",
        "    model=genai.GenerativeModel('gemini-pro')\n",
        "    response=model.generate_content(input)\n",
        "    return response.text\n",
        "\n",
        "def input_pdf_text(uploaded_file):\n",
        "    reader=pdf.PdfReader(uploaded_file)\n",
        "    text=\"\"\n",
        "    for page in range(len(reader.pages)):\n",
        "        page=reader.pages[page]\n",
        "        text+=str(page.extract_text())\n",
        "    return\n",
        "\n",
        "def input_docx_text():\n",
        "    # Prompt the user to upload a file\n",
        "    print(\"Please upload a .docx file:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Get the uploaded filename\n",
        "    filename = list(uploaded.keys())[0]\n",
        "\n",
        "    # Read the uploaded file\n",
        "    doc = Document(filename)\n",
        "\n",
        "    full_text = []\n",
        "    for para in doc.paragraphs:\n",
        "        full_text.append(para.text)\n",
        "\n",
        "    return '\\n'.join(full_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # model=genai.GenerativeModel('gemini-pro')\n",
        "    # response=model.generate_content('Hi')\n",
        "    # print(response.text)"
      ],
      "metadata": {
        "id": "Y1Y0GfQCQfZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jd= \"\"\"\n",
        "G2 is where you go for software. When you join us, you join the global team behind the largest and most trusted software marketplace. Every month, 5.5 million people come to G2 to inform smarter software decisions based on honest peer reviews. Authenticity is our focus, and every day we help thousands of companies, and hundreds of employees, propel their potential. Ready for meaningful work that starts and ends with compassion and heart? You’ve come to the right place.\n",
        "\n",
        "G2 is going through exciting growth! We’ve recently secured our Series D funding of $157 million, which will further allow us to grow and develop our product and people. Read about it here !\n",
        "\n",
        "About G2 - Our People\n",
        "\n",
        "G2 was founded to create a place where people will love to work. We have big goals, and are grounded in our PEAK values—high performance and entrepreneurship, while also being authentic and kind. Employees are led by conscious leaders who are connected by shared commitments and 7 core leadership principles. We celebrate each other's successes, forgive mistakes, and support one another during challenging times. Together, we will grow and reach the top, while staying true to our values, ethics, and people.\n",
        "\n",
        "As we foster our high-performance and entrepreneurial culture, we strive to create meaning in work and provide more than just a job: a true calling. At the heart of our community and culture are our people. Our global G2 team comes from a wide range of backgrounds and experiences, and that’s what makes our G2 community strong and vibrant. We want everyone to bring their authentic selves to work, and we do this through our company and team events, our G2 Gives charitable initiatives, and our Employee Resource Groups (ERGs).\n",
        "\n",
        "We support our employees by offering generous benefits, such as flexible work, ample parental leave. Click here to learn more about our benefits.\n",
        "\n",
        "This is a hybrid position, with the team meeting in person two days a week at our Bengaluru office.\n",
        "\n",
        "About The Role\n",
        "\n",
        "As a Senior Machine Learning Engineer, you'll play a key role in deploying machine learning models, establishing efficient MLOps practices, driving data engineering initiatives, and developing a scalable ML platform. Your responsibilities include deploying models seamlessly into production systems, optimizing them for performance, architecting MLOps pipelines for streamlined operations, and establishing a robust ML platform.\n",
        "\n",
        "In this role, you will:-\n",
        "\n",
        "Data/ML Pipelines And Deployment\n",
        "\n",
        "Own the end-to-end deployment process for ML models, ensuring seamless integration into production systems.Optimize models for performance, scalability, and resource efficiency.Drive data engineering efforts, designing and optimizing scalable data pipelines for machine learning services.Develop and maintain robust ML/Data engineering processes, ensuring high data quality and reliability.\n",
        "Work with cross-functional teams to integrate the machine learning services into the product.\n",
        "\n",
        "MLOps And Platform\n",
        "\n",
        "Lead the design and implementation of a scalable ML platform, facilitating efficient model development and deployment.Architect infrastructure in support of rapid experimentation and evolving requirements.Implement CI/CD pipelines to ensure continuous integration and deployment of ML models.\n",
        "Establish MLOps pipelines, automating model training, deployment, and monitoring processes.\n",
        "Implement engineering standards and best practices.\n",
        "\n",
        " Mentorship and Guidance (20%):\n",
        "\n",
        "Provide technical guidance to the team, enabling skill development and fostering best practices.Guide the data science team with the latest MLOps practices.\n",
        "Collaborate with larger engineering team to facilitate brainstorming sessions and ideate on platform best practices\n",
        "\n",
        "Requirements:-\n",
        "\n",
        "6+ years of experience in the field of machine learning engineering.\n",
        "4+ years of hands-on experience in deploying ML models and MLOps practices.\n",
        "2+ years of experience in data engineering.\n",
        "Proficiency in Python, coupled with hands-on experience in ML frameworks such as Tensorflow, Scikit-Learn, and PyTorch.\n",
        "Expertise in designing scalable data and ML pipelines.\n",
        "Experience in managing ML infrastructure.\n",
        "Hands-on experience with Docker, Kubernetes, and Helm.\n",
        "Hands-on experience with SQL/No-SQL\n",
        "Hands-on experience with AWS/Azure Data/ML-related services.\n",
        "Hands-on experience with Flask/FastAPI/Django REST services.\n",
        "Thorough understanding of distributed systems and design patterns.\n",
        "Proficiency in tools like MLFlow, DVC, Kubeflow, and Airflow.\n",
        "Experience in startup environments.\n",
        "Experience as Machine Learning Engineer or Architect.\n",
        "Experience in System Design.\n",
        "Experience in Platform Engineering and Related Concepts.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "tupiGlCvTIm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resume=input_docx_text()\n",
        "print(resume)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qATBrU0bURsO",
        "outputId": "a9f9edcd-be1d-423b-e61f-0d5443827ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload a .docx file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3ffe570c-faa4-48d6-9bd4-84bdc4c0969a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3ffe570c-faa4-48d6-9bd4-84bdc4c0969a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving MasterResume.docx to MasterResume (2).docx\n",
            "Md Azharuddin Mondul \n",
            "Machine Learning Engineer\n",
            "\n",
            "\n",
            "azmd801@gmail.com\n",
            "\n",
            "\n",
            "  8830344859\n",
            "\n",
            "\n",
            "linkedin.com/in/azmd801\n",
            "\n",
            "  https://github.com/azmd801 \n",
            "\n",
            "\n",
            "Profile\n",
            "\n",
            "Experienced Machine Learning Engineer and Data Scientist with a demonstrated ability and track record in developing and deploying full-stack data science projects. I possess hands-on experience in effectively leveraging machine learning, deep learning, transfer learning and Generative AI (Gen AI) models to tackle challenging business problems.\n",
            "\n",
            "Skill\n",
            "\n",
            "\n",
            "\n",
            "Python: Pandas | Numpy |flask | Fast API | boto3\n",
            "Statistics: Descriptive statistics | Inferential statistics | Hypothesis Testing |\n",
            "Data Visualization: Matplotlib | Seaborn| EDA | Pandas profiling\n",
            "Machine Learning: Supervised Learning | Classification | Regression | Scikit-learn | Unsupervised Learning | Hyper-parameter tuning\n",
            "Natural Language Processing (NLP): NLTK | spaCy | Gensim | Word2Vec | Chatbots\n",
            "Large Language Model: LangChain | Chainlit | LlamaIndex | Hugging Face | Retrieval-Augmented Generation (RAG) | OpenAI | Gemini | Llama 2 | Gen AI | BERT | GPT\n",
            "Cloud Technology: AWS | S3 Bucket | EC2 | ECR | Elastic Beanstalk | cloud computing\n",
            "Deep Learning: ANN | CNN | RNN | LSTM | GRU | Transformer | Encoder Decoder | Generative AI | TensorFlow | Keras | PyTorch\n",
            "Version Control Tools: Git | Github\n",
            "Deployment: Docker | Continuous Integration and Continuous Deployment | CI/CD | GitHub Actions | Model Serving\n",
            "Database: MYSQL | MongoDB | Vector Database | Pinecone | Chroma DB\n",
            "\n",
            "\n",
            "\n",
            "Experience\n",
            "\n",
            "\n",
            "Machine Learning Engineer\n",
            "\n",
            "\n",
            "Quest Global\n",
            "\n",
            "Jul 2021 - Present \n",
            "\n",
            "Chat with Email using local LLM\n",
            "Developed an innovative Retrieval Augmented Generation (RAG) based conversational chat application, empowering users to seamlessly interact with customer’s emails, generating summaries, understanding sentiment, searching for information significantly boosting customer’s engagement and satisfaction.\n",
            "Utilized open source Large Language Model (LLM)- Llama 2 for text generation and embedding text, Utilized LangChain framework for the development and deployment of the application and Vector Database-Chroma DB, for seamless storage and retrieval of relevant email information based on contextual similarity\n",
            "Predictive Maintenance for Aircraft Engines using LSTM: \n",
            "Developed a Predictive Maintenance application forecasting the remaining useful life of aircraft engines, achieving a 20% reduction in reported component failures.\n",
            "Leveraged data from multiple sensors collected during flight cycles for comprehensive model training and analysis, utilized LSTM architecture for effective temporal sequence learning and Utilized Keras Tuner to fine-tune the model parameters finding the best model\n",
            "Deployed the application on Windows using PyInstaller for creating a standalone executable.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Mode Shape Detection using Computer Vision: \n",
            "Supported the computer vision team in developing a CNN-based tool for automating the detection of mode shapes of engine blades, resulting in a 90% reduction in manual effort and processing time.\n",
            "Utilized a fine-tuned pre-trained vision model (EfficientNetB0) to classify images into five mode categories.\n",
            "Utilized dataset consisting of over 14,000 labeled images obtained from engineering analysis of engine blades for training purposes and Deployed on Windows using PyInstaller for creating a standalone executable.\n",
            "\n",
            "Open Source Project\n",
            "\n",
            "Back Order Prediction Deployment \n",
            "\n",
            "Developed and deployed a machine learning-based application for backorder prediction, enabling businesses to anticipate and mitigate potential shortages. The system utilizes a predictive model that analyzes historical order data, inventory levels, and lead times, providing customers with actionable insights to proactively address and reduce the risk of business losses.\n",
            "Conducted in-depth Exploratory Data Analysis (EDA) using the Pandas profiling library to guide strategic feature selection and engineering. \n",
            "Utilized Optuna library for model selection  and hyper-parameter tuning, returning finely tuned model XGboost classifier with impressive over 80% balanced accuracy. \n",
            "Developed a modular machine learning pipeline and exposed it as an API using FastAPI for training and prediction. \n",
            "Utilized MongoDB for efficient dataset storage and retrieval, S3 bucket for efficient model storage and serving. \n",
            "Automated the deployment process by seamlessly integrating a CI/CD pipeline with GitHub Actions \n",
            "\n",
            "Project repo link: https://github.com/azmd801/back_order_prediction_end2end\n",
            "\n",
            "\n",
            "Courses and Certification\n",
            "\n",
            "Full Stack Data Science BootCamp 2.0\n",
            "  \n",
            "Mastered the entire data science pipeline, from data ingestion to deploying machine learning models using a CI/CD pipeline. Gained hands-on experience with real-world projects, learned the latest tools, and connected with a vibrant community of data science professionals.\n",
            "\n",
            "Credential ID: https://learn.ineuron.ai/certi_cate/6227645e-fd2d-44fd-88fc-58da3f0ca7ae\n",
            "\n",
            "Education\n",
            "\n",
            "\n",
            "Birla Institute of Technology and Science, Pilani Master in engineering, Design Engineering\n",
            "\n",
            "2018 - 2020\n",
            "\n",
            "\n",
            "Haldia Institute of Technology\n",
            "\n",
            "\n",
            "Btech, Mechanical Engineering\n",
            "\n",
            "2013 - 2017\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text = resume\n",
        "text = jd"
      ],
      "metadata": {
        "id": "diAlsrZIYdzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_prompt=f\"\"\"\n",
        "Your an adavanced smart ATS system with deep knowledege\n",
        "of DATA SCEINCE and MACHINE LEARNING, your task is to extract all\n",
        "important job related key words from given {text} extract keywords from provided text\n",
        "ony dont add any thing from yourself,\n",
        "\n",
        "and return output in string format all keywords separated by comma\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "GSXsAF7UZlHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQBLsIeSal4y",
        "outputId": "1be510a4-1f57-4887-e8fe-e7ce027620bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Your an adavanced smart ATS system with deep knowledege\n",
            "of DATA SCEINCE and MACHINE LEARNING, your task is to extract all \n",
            "important job related key words from given \n",
            "G2 is where you go for software. When you join us, you join the global team behind the largest and most trusted software marketplace. Every month, 5.5 million people come to G2 to inform smarter software decisions based on honest peer reviews. Authenticity is our focus, and every day we help thousands of companies, and hundreds of employees, propel their potential. Ready for meaningful work that starts and ends with compassion and heart? You’ve come to the right place.\n",
            "\n",
            "G2 is going through exciting growth! We’ve recently secured our Series D funding of $157 million, which will further allow us to grow and develop our product and people. Read about it here !\n",
            "\n",
            "About G2 - Our People\n",
            "\n",
            "G2 was founded to create a place where people will love to work. We have big goals, and are grounded in our PEAK values—high performance and entrepreneurship, while also being authentic and kind. Employees are led by conscious leaders who are connected by shared commitments and 7 core leadership principles. We celebrate each other's successes, forgive mistakes, and support one another during challenging times. Together, we will grow and reach the top, while staying true to our values, ethics, and people.\n",
            "\n",
            "As we foster our high-performance and entrepreneurial culture, we strive to create meaning in work and provide more than just a job: a true calling. At the heart of our community and culture are our people. Our global G2 team comes from a wide range of backgrounds and experiences, and that’s what makes our G2 community strong and vibrant. We want everyone to bring their authentic selves to work, and we do this through our company and team events, our G2 Gives charitable initiatives, and our Employee Resource Groups (ERGs).\n",
            "\n",
            "We support our employees by offering generous benefits, such as flexible work, ample parental leave. Click here to learn more about our benefits.\n",
            "\n",
            "This is a hybrid position, with the team meeting in person two days a week at our Bengaluru office.\n",
            "\n",
            "About The Role\n",
            "\n",
            "As a Senior Machine Learning Engineer, you'll play a key role in deploying machine learning models, establishing efficient MLOps practices, driving data engineering initiatives, and developing a scalable ML platform. Your responsibilities include deploying models seamlessly into production systems, optimizing them for performance, architecting MLOps pipelines for streamlined operations, and establishing a robust ML platform.\n",
            "\n",
            "In this role, you will:- \n",
            "\n",
            "Data/ML Pipelines And Deployment\n",
            "\n",
            "Own the end-to-end deployment process for ML models, ensuring seamless integration into production systems.Optimize models for performance, scalability, and resource efficiency.Drive data engineering efforts, designing and optimizing scalable data pipelines for machine learning services.Develop and maintain robust ML/Data engineering processes, ensuring high data quality and reliability.\n",
            "Work with cross-functional teams to integrate the machine learning services into the product.\n",
            "\n",
            "MLOps And Platform\n",
            "\n",
            "Lead the design and implementation of a scalable ML platform, facilitating efficient model development and deployment.Architect infrastructure in support of rapid experimentation and evolving requirements.Implement CI/CD pipelines to ensure continuous integration and deployment of ML models.\n",
            "Establish MLOps pipelines, automating model training, deployment, and monitoring processes.\n",
            "Implement engineering standards and best practices.\n",
            "\n",
            " Mentorship and Guidance (20%): \n",
            "\n",
            "Provide technical guidance to the team, enabling skill development and fostering best practices.Guide the data science team with the latest MLOps practices.\n",
            "Collaborate with larger engineering team to facilitate brainstorming sessions and ideate on platform best practices\n",
            "\n",
            "Requirements:- \n",
            "\n",
            "6+ years of experience in the field of machine learning engineering.\n",
            "4+ years of hands-on experience in deploying ML models and MLOps practices.\n",
            "2+ years of experience in data engineering.\n",
            "Proficiency in Python, coupled with hands-on experience in ML frameworks such as Tensorflow, Scikit-Learn, and PyTorch.\n",
            "Expertise in designing scalable data and ML pipelines.\n",
            "Experience in managing ML infrastructure.\n",
            "Hands-on experience with Docker, Kubernetes, and Helm.\n",
            "Hands-on experience with SQL/No-SQL\n",
            "Hands-on experience with AWS/Azure Data/ML-related services.\n",
            "Hands-on experience with Flask/FastAPI/Django REST services.\n",
            "Thorough understanding of distributed systems and design patterns.\n",
            "Proficiency in tools like MLFlow, DVC, Kubeflow, and Airflow.\n",
            "Experience in startup environments.\n",
            "Experience as Machine Learning Engineer or Architect.\n",
            "Experience in System Design.\n",
            "Experience in Platform Engineering and Related Concepts.\n",
            "\n",
            " extract keywords from provided text\n",
            "ony dont add any thing from yourself,\n",
            "\n",
            "and return output in string format all keywords separated by comma\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_gemini_repsonse(input_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "8V5UfU1laPRE",
        "outputId": "721ef2fc-028f-4db5-b5e7-4dc03510ed87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Senior Machine Learning Engineer, Data/ML Pipelines And Deployment, MLOps And Platform, Mentorship and Guidance, Machine learning engineering, MLOps practices, Data engineering, Python, ML frameworks, Tensorflow, Scikit-Learn, PyTorch, Scalable data, ML pipelines, ML infrastructure, Docker, Kubernetes, Helm, SQL/No-SQL, AWS/Azure Data/ML-related services, Flask/FastAPI/Django REST services, Distributed systems, Design patterns, MLFlow, DVC, Kubeflow, Airflow, Startup environments, System Design, Platform Engineering'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_gemini_repsonse(input_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "zukYgHYFSmrt",
        "outputId": "5fccb2a2-9084-4c6a-d200-f94e1a8f3542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Machine Learning Engineer, Data Scientist, Python, Pandas, Numpy, Flask, Fast API, boto3, Statistics, Descriptive statistics, Inferential statistics, Hypothesis Testing, Data Visualization, Matplotlib, Seaborn, EDA, Pandas profiling, Machine Learning, Supervised Learning, Classification, Regression, Scikit-learn, Unsupervised Learning, Hyper-parameter tuning, Natural Language Processing (NLP), NLTK, spaCy, Gensim, Word2Vec, Chatbots, Large Language Model, LangChain, Chainlit, LlamaIndex, Hugging Face, Retrieval-Augmented Generation (RAG), OpenAI, Gemini, Llama 2, Gen AI, BERT, GPT, Cloud Technology, AWS, S3 Bucket, EC2, ECR, Elastic Beanstalk, Cloud computing, Deep Learning, ANN, CNN, RNN, LSTM, GRU, Transformer, Encoder Decoder, Generative AI, TensorFlow, Keras, PyTorch, Version Control Tools, Git, Github, Deployment, Docker, Continuous Integration and Continuous Deployment, CI/CD, GitHub Actions, Model Serving, Database, MySQL, MongoDB, Vector Database, Pinecone, Chroma DB'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    }
  ]
}